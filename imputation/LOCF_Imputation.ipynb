{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LOCF IMPUTATION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports \n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import itertools \n",
    "import matplotlib.pyplot as plt\n",
    "import copy\n",
    "\n",
    "# Auxiliar functions\n",
    "from aux import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.max_rows', 500)\n",
    "pd.options.display.max_columns = 2000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read all the data after fix: num_installs, macro android version,has, what's new, clean dev address\n",
    "all_apps2= pd.read_csv(\"PATH.csv\", delimiter=\"\\t\", encoding='utf-8', engine= 'python',converters={'_id':str})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Obtain basic infomation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_category = all_apps2.clean_category.unique()\n",
    "top = all_apps2.top.unique()\n",
    "countries = all_apps2.country.unique()\n",
    "\n",
    "# Retrieve different dates as str\n",
    "retrieved_date_data = all_apps2.retrieved_date_end.unique()\n",
    "retrieved_date_data.sort()\n",
    "\n",
    "# List combination between tops and category\n",
    "clean_cat_no_editorChoice = np.delete(clean_category, np.where(clean_category == \"editorChoice\"))\n",
    "\n",
    "list_combinations = [top[0:2], clean_cat_no_editorChoice]\n",
    "top_category_combination = [p for p in itertools.product(*list_combinations)]\n",
    "\n",
    "top_category_combination.append(('editorChoice','')) # list with all the possible top and category combinations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Adding some auxiliar columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Column to differentiate  general category vs all\n",
    "condition = [all_apps2['clean_category']=='general']\n",
    "output = [1]\n",
    "all_apps2['General'] = pd.Series(np.select(condition, output, 0))\n",
    "\n",
    "# A falg just for aggregations\n",
    "all_apps2['Flag'] = 1 # just a number to flag the pivot tables\n",
    "all_apps2['Delete']= 0 # 0 means that we do NOT need to delete this data\n",
    "all_apps2['imputed'] = 0 # 0 means that is original data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data from missing weeks per country-category"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "missing_apps_cat_country = pd.DataFrame(index= top_category_combination, dtype= str, columns= countries)\n",
    "missing_num_cat_country = pd.DataFrame(index= top_category_combination, columns= countries, data= np.zeros((len(top_category_combination), len(countries))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dictionaries by country - top and category"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create a data frame dictionary to store data frames by countries\n",
    "df_countries = {elem : pd.DataFrame for elem in countries}\n",
    "for country in df_countries.keys():\n",
    "    df_countries[country] = all_apps2[:][all_apps2.country == country]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Empty dictionaries\n",
    "dict_co_cate = {elem : pd.DataFrame for elem in top_category_combination}\n",
    "dict_usa_cate = {elem : pd.DataFrame for elem in top_category_combination}\n",
    "dict_br_cate = {elem : pd.DataFrame for elem in top_category_combination}\n",
    "dict_de_cate = {elem : pd.DataFrame for elem in top_category_combination}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "create_dataFrames_by_category(df_countries['co'], dict_co_cate)\n",
    "create_dataFrames_by_category(df_countries['us'], dict_usa_cate)\n",
    "create_dataFrames_by_category(df_countries['br'], dict_br_cate)\n",
    "create_dataFrames_by_category(df_countries['de'], dict_de_cate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#BR\n",
    "print('BR')\n",
    "dict_pivot_cat_br2, incomplete_br =  pivot_sum_top(dict_br_cate,retrieved_date_data,'br',missing_num_cat_country, missing_apps_cat_country)\n",
    "#CO\n",
    "print('CO')\n",
    "dict_pivot_cat_co2, incomplete_co =  pivot_sum_top(dict_co_cate,retrieved_date_data,'co',missing_num_cat_country,missing_apps_cat_country)\n",
    "#DE\n",
    "print('DE')\n",
    "dict_pivot_cat_de2, incomplete_de =  pivot_sum_top(dict_de_cate,retrieved_date_data,'de',missing_num_cat_country, missing_apps_cat_country)\n",
    "#US\n",
    "print('US')\n",
    "dict_pivot_cat_usa2, incomplete_usa =  pivot_sum_top(dict_usa_cate,retrieved_date_data,'us',missing_num_cat_country, missing_apps_cat_country)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "join_sumary_data = missing_num_cat_country.join(missing_apps_cat_country, lsuffix='_sum', rsuffix='_list')\n",
    "#join_sumary_data.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dates for imputation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dates = ['2017-11-11', '2017-11-18', '2017-11-25', '2017-12-02','2017-12-09', '2017-12-16', '2017-12-23', '2017-12-30','2018-01-06',\n",
    "         '2018-01-13', '2018-01-20', '2018-01-27','2018-02-03', '2018-02-10', '2018-02-17', '2018-02-24','2018-03-03', '2018-03-10', \n",
    "         '2018-03-17', '2018-03-24','2018-03-31', '2018-04-07', '2018-04-14', '2018-04-21','2018-04-28', '2018-05-05', '2018-05-12', \n",
    "         '2018-05-19', '2018-05-26', '2018-06-02']\n",
    "retrieved_date= ['2017-11-05', '2017-11-12', '2017-11-19', '2017-11-26',\n",
    "       '2017-12-03', '2017-12-10', '2017-12-17', '2017-12-24',\n",
    "       '2017-12-31', '2018-01-07', '2018-01-14', '2018-01-21',\n",
    "       '2018-01-28', '2018-02-04', '2018-02-11', '2018-02-18',\n",
    "       '2018-02-25', '2018-03-04', '2018-03-11', '2018-03-18',\n",
    "       '2018-03-25', '2018-04-01', '2018-04-08', '2018-04-15',\n",
    "       '2018-04-22', '2018-04-29', '2018-05-06', '2018-05-13',\n",
    "       '2018-05-20', '2018-05-27'] \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "original_all_apps = copy.deepcopy(all_apps2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "original_all_apps[original_all_apps.top=='editorChoice'].head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "general_keep =join_sumary_data[(join_sumary_data.br_sum <=3) & (join_sumary_data.co_sum <=3) & (join_sumary_data.de_sum <=3) & (join_sumary_data.us_sum <=3)]\n",
    "general_delete =join_sumary_data[(join_sumary_data.br_sum >3) | (join_sumary_data.co_sum >3) | (join_sumary_data.de_sum >3) | (join_sumary_data.us_sum >3)]\n",
    "g_cat_keep= list(general_keep.index)\n",
    "g_cat_delete= list(general_delete.index)\n",
    "\n",
    "# per country\n",
    "g_cat_br_delete = list(join_sumary_data[ (join_sumary_data.br_sum >3)].index)\n",
    "g_cat_co_delete = list(join_sumary_data[ (join_sumary_data.co_sum >3)].index)\n",
    "g_cat_usa_delete = list(join_sumary_data[ (join_sumary_data.us_sum >3)].index)\n",
    "g_cat_de_delete = list(join_sumary_data[ (join_sumary_data.de_sum >3)].index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Categories that we want to keep for analysis\n",
    "for i in range(0,31):\n",
    "    categories =join_sumary_data[(join_sumary_data.br_sum >i)|(join_sumary_data.co_sum >i)|(join_sumary_data.de_sum >i)|(join_sumary_data.us_sum >i)]\n",
    "    num= categories.shape[0]\n",
    "    total= join_sumary_data.shape[0] \n",
    "    print(f'for {i} we deleted {num}, {round((num/total)*100,2)}')\n",
    "    print(f'         kept {total - num}, {round(((total -num)/total)*100,2)}')   \n",
    "    \n",
    "    if i >=1:\n",
    "        print(list(categories.index))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def app_imputation_LOCF(row,country,id_app,category,dates,all_apps,ii,retrieved_date):\n",
    "    \"\"\"Imputes data  WITH LOCF\n",
    "    \"\"\"\n",
    "    imputed = 0\n",
    "    new_data = []\n",
    "    all_apps = all_apps.loc[(all_apps.id == id_app)& (all_apps.country==country)&(all_apps.top==category[0])]\n",
    "    for i in range(0,len(row)):\n",
    "        if np.isnan(row[i]):\n",
    "            if i == 0:\n",
    "                # if first week is not available then is going to be 0\n",
    "                print(\"primera fila\")\n",
    "                row[i] = 0\n",
    "            elif i >0:\n",
    "                row[i] = row[i-1]\n",
    "                if row[i] == 1:\n",
    "                    #print(ii,id_app,category,country, dates[i])\n",
    "                    if category[0] == '':\n",
    "                        app = all_apps.loc[(all_apps.retrieved_date_end==dates[i-1])].copy()\n",
    "                    else:\n",
    "                        app = all_apps.loc[(all_apps.retrieved_date_end==dates[i-1]) & (all_apps.clean_category==category[1])].copy()\n",
    "                    app['retrieved_date_end'] = dates[i]\n",
    "                    app['retrieved_date_start'] = retrieved_date[i]\n",
    "\n",
    "\n",
    "                    app['imputed'] = 1\n",
    "                    imputed +=1 \n",
    "\n",
    "                    all_apps = pd.concat([all_apps, app], sort=False,ignore_index=True, copy=False)\n",
    "                    new_data.append(app)\n",
    "\n",
    "\n",
    "    return row , new_data,imputed"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Colombia"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "g_cat_co_delete"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(\"++\")\n",
    "temp_all_apps = []\n",
    "imputados= 0\n",
    "for key, data in dict_pivot_cat_co2.items():\n",
    "    #columns = dict_pivot_cat_co2[key][].columns\n",
    "    \n",
    "    if  key not in g_cat_co_delete:\n",
    "        index = dict_pivot_cat_co2[key].index\n",
    "        new_data = []\n",
    "        \n",
    "        for ind, value in enumerate(data[dates].values):\n",
    "            row, new_all_apps,total = app_imputation_LOCF(value,'co',index[ind],key,dates,original_all_apps,ind,retrieved_date)\n",
    "            new_data.append(row)\n",
    "            imputados+=total\n",
    "            if len(new_all_apps)>0:\n",
    "                temp_all_apps.extend(new_all_apps)\n",
    "        dict_pivot_cat_co2[key] = pd.DataFrame(columns=dates,data=new_data, index=index)\n",
    "    print(key)\n",
    "\n",
    "print(\"++\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_apps_co = pd.concat(temp_all_apps, sort=False,ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(temp_all_apps),imputados,new_apps_co.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_apps_co.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Brazil"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "g_cat_br_delete"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(original_all_apps.shape)\n",
    "print(\"++\")\n",
    "temp_all_apps = []\n",
    "imputados= 0\n",
    "for key, data in dict_pivot_cat_br2.items():\n",
    "    \n",
    "    if  key not in g_cat_br_delete:\n",
    "        index = dict_pivot_cat_br2[key].index\n",
    "        new_data = []\n",
    "        \n",
    "        for ind, value in enumerate(data[dates].values):\n",
    "            row, new_all_apps,total = app_imputation_LOCF(value,'br',index[ind],key,dates,original_all_apps,ind,retrieved_date)\n",
    "            new_data.append(row)\n",
    "            imputados+=total\n",
    "            if len(new_all_apps)>0:\n",
    "                temp_all_apps.extend(new_all_apps)\n",
    "        dict_pivot_cat_br2[key] = pd.DataFrame(columns=dates,data=new_data, index=index)\n",
    "    print(key)\n",
    "\n",
    "print(\"++\")\n",
    "print(original_all_apps.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(temp_all_apps),imputados)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if len(temp_all_apps)>0:\n",
    "    new_apps_br = pd.concat(temp_all_apps, sort=False,ignore_index=True)\n",
    "    print(len(temp_all_apps),imputados,new_apps_usa.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## USA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "g_cat_usa_delete"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"++\")\n",
    "temp_all_apps = []\n",
    "imputados= 0\n",
    "for key, data in dict_pivot_cat_usa2.items():\n",
    "    \n",
    "    if  key not in g_cat_usa_delete:\n",
    "        index = dict_pivot_cat_usa2[key].index\n",
    "        new_data = []\n",
    "        \n",
    "        for ind, value in enumerate(data[dates].values):\n",
    "            row, new_all_apps,total = app_imputation_LOCF(value,'us',index[ind],key,dates,original_all_apps,ind,retrieved_date)\n",
    "            new_data.append(row)\n",
    "            imputados+=total\n",
    "            if len(new_all_apps)>0:\n",
    "                temp_all_apps.extend(new_all_apps)\n",
    "        dict_pivot_cat_usa2[key] = pd.DataFrame(columns=dates,data=new_data, index=index)\n",
    "    print(key)\n",
    "\n",
    "print(\"++\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(temp_all_apps),imputados)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if len(temp_all_apps)>0:\n",
    "    new_apps_usa = pd.concat(temp_all_apps, sort=False,ignore_index=True)\n",
    "    print(len(temp_all_apps),imputados,new_apps_usa.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Germany"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "g_cat_de_delete"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(\"++\")\n",
    "temp_all_apps = []\n",
    "imputados= 0\n",
    "for key, data in dict_pivot_cat_de2.items():\n",
    "    \n",
    "    if  key not in g_cat_de_delete:\n",
    "        index = dict_pivot_cat_de2[key].index\n",
    "        new_data = []\n",
    "        \n",
    "        for ind, value in enumerate(data[dates].values):\n",
    "            row, new_all_apps,total = app_imputation_LOCF(value,'de',index[ind],key,dates,original_all_apps,ind,retrieved_date)\n",
    "            new_data.append(row)\n",
    "            imputados+=total\n",
    "            if len(new_all_apps)>0:\n",
    "                temp_all_apps.extend(new_all_apps)\n",
    "        dict_pivot_cat_de2[key] = pd.DataFrame(columns=dates,data=new_data, index=index)\n",
    "    print(key)\n",
    "\n",
    "print(\"++\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(temp_all_apps),imputados)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if len(temp_all_apps)>0:\n",
    "    new_apps_de = pd.concat(temp_all_apps, sort=False,ignore_index=True)\n",
    "    print(len(temp_all_apps),imputados,new_apps_de.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_apps3 = pd.concat([new_apps_de,new_apps_co,original_all_apps], sort=False,ignore_index=True)\n",
    "all_apps3.shape, original_all_apps.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "g_cat_delete"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "g_cat_co_delete"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "g_cat_br_delete"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "g_cat_usa_delete"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "g_cat_de_delete"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_apps3['Delete'] = all_apps3[['clean_category','top']].apply (lambda row: delete_flag(row, g_cat_delete), axis=1)\n",
    "all_apps3['Delete_bo'] = all_apps3[['clean_category','top']].apply (lambda row: delete_flag(row, g_cat_co_delete), axis=1)\n",
    "all_apps3['Delete_br'] = all_apps3[['clean_category','top']].apply (lambda row: delete_flag(row, g_cat_br_delete), axis=1)\n",
    "all_apps3['Delete_de'] = all_apps3[['clean_category','top']].apply (lambda row: delete_flag(row, g_cat_de_delete), axis=1)\n",
    "all_apps3['Delete_usa'] = all_apps3[['clean_category','top']].apply (lambda row: delete_flag(row, g_cat_usa_delete), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_apps3.to_csv('data_LOCF.csv', sep='\\t', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
