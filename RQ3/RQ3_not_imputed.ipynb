{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RQ3 not imputed data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "%matplotlib inline\n",
    "import datetime\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import math\n",
    "import csv\n",
    "from ast import literal_eval\n",
    "# Jupyter configurations\n",
    "pd.options.display.max_columns = 2000\n",
    "\n",
    "# Imports \n",
    "import itertools \n",
    "\n",
    "\n",
    "# Stats\n",
    "from scipy.stats import mannwhitneyu\n",
    "from statsmodels.sandbox.stats.multicomp import multipletests\n",
    "import cliffsDelta # implementation\n",
    "\n",
    "# Graphics \n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Auxiliar functions\n",
    "from aux import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read all the data after fix: num_installs, macro android version,has, what's new, clean dev address\n",
    "all_apps = pd.read_csv(\"PATH.csv\", delimiter=\"\\t\", encoding='utf-8', engine= 'python',converters={'_id':str})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_apps.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_apps.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get unique values - basic information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Unique values \n",
    "countries = all_apps.country.unique()\n",
    "top = all_apps.top.unique()\n",
    "clean_category = all_apps.clean_category.unique()\n",
    "\n",
    "\n",
    "# Retrieve different dates as str\n",
    "retrieved_date_data = all_apps.retrieved_date_end.unique()\n",
    "retrieved_date_data.sort()\n",
    "\n",
    "# List combination between tops and category\n",
    "clean_cat_no_editorChoice = np.delete(clean_category, np.where(clean_category == \"editorChoice\"))\n",
    "\n",
    "list_combinations = [top[0:2], clean_cat_no_editorChoice]\n",
    "top_category_combination = [p for p in itertools.product(*list_combinations)]\n",
    "\n",
    "top_category_combination.append(('editorChoice','')) # list with all the possible top and category combinations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### set color palette"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set colors for grpahics\n",
    "seq_col_brew = sns.color_palette(\"Greys_r\", 5)\n",
    "sns.set_palette(seq_col_brew)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create dictionaries for each of the 268 possible combinations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create a data frame dictionary to store data frames by countries\n",
    "df_countries = {elem : pd.DataFrame for elem in countries}\n",
    "for country in df_countries.keys():\n",
    "    df_countries[country] = all_apps[:][all_apps.country == country]\n",
    "\n",
    "#Dict for each country and category\n",
    "dict_co_cate = {elem : pd.DataFrame for elem in top_category_combination}\n",
    "dict_usa_cate = {elem : pd.DataFrame for elem in top_category_combination}\n",
    "dict_br_cate = {elem : pd.DataFrame for elem in top_category_combination}\n",
    "dict_de_cate = {elem : pd.DataFrame for elem in top_category_combination}\n",
    "\n",
    "#create 67 dataframes for each country\n",
    "create_dataFrames_by_category(df_countries['co'], dict_co_cate)\n",
    "create_dataFrames_by_category(df_countries['us'], dict_usa_cate)\n",
    "create_dataFrames_by_category(df_countries['br'], dict_br_cate)\n",
    "create_dataFrames_by_category(df_countries['de'], dict_de_cate)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pivot Tables"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TLO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#missing weeks summary\n",
    "missing_apps_cat_country = pd.DataFrame(index= top_category_combination, dtype= str, columns= countries)\n",
    "missing_num_cat_country = pd.DataFrame(index= top_category_combination, columns= countries, data= np.zeros((len(top_category_combination), len(countries))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# df, number -> df gives a dictionary with the pivot categories vs apps (1 appears, 0 not appears, NAN missing value)\n",
    "dict_pivot_cat_br, incomplete_br =  pivot_sum_top(dict_br_cate,retrieved_date_data,'br',missing_num_cat_country,missing_apps_cat_country)\n",
    "dict_pivot_cat_co, incomplete_co =  pivot_sum_top(dict_co_cate,retrieved_date_data,'co',missing_num_cat_country,missing_apps_cat_country)\n",
    "dict_pivot_cat_de, incomplete_de =  pivot_sum_top(dict_de_cate,retrieved_date_data,'de',missing_num_cat_country,missing_apps_cat_country)\n",
    "dict_pivot_cat_usa, incomplete_usa =  pivot_sum_top(dict_usa_cate,retrieved_date_data,'us',missing_num_cat_country,missing_apps_cat_country)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(incomplete_br, incomplete_co, incomplete_de, incomplete_usa)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_df_occurrences(dict_country, country, final_list):\n",
    "\n",
    "    for (top,category), data in  dict_country.items():\n",
    "        df = pd.DataFrame(columns=['Top','Category','Occurrences','Country'])\n",
    "\n",
    "        df['Occurrences']= data['occurrences']\n",
    "        df['Country']= country.upper()\n",
    "        df['Top']= top\n",
    "        df['Category']= category\n",
    "                                   \n",
    "        final_list.append(df)\n",
    "        \n",
    "lst_occurences = []\n",
    "create_df_occurrences(dict_pivot_cat_br,'br',lst_occurences)\n",
    "create_df_occurrences(dict_pivot_cat_co,'co',lst_occurences)\n",
    "create_df_occurrences(dict_pivot_cat_de,'de',lst_occurences)\n",
    "create_df_occurrences(dict_pivot_cat_usa,'us',lst_occurences)\n",
    "\n",
    "#dataframe with the information about number od occurences (how many times an app appears in the top)\n",
    "df_occurences_countries = pd.concat(lst_occurences) \n",
    "df_occurences_countries['Type'] = 'TLO'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## EST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#----- EST\n",
    "def count_durations_by_appearance(row, count_list):\n",
    "    count = 0\n",
    "    appear = False\n",
    "\n",
    "    for i in range(0,len(row)):\n",
    "        \n",
    "        if (not appear and not np.isnan(row[i]) and row[i]==1) :\n",
    "            appear = True\n",
    "\n",
    "        if ((np.isnan(row[i]) or row[i] ==0 ) and appear) :\n",
    "            appear = False\n",
    "            count_list.append(count)\n",
    "            count = 0\n",
    "            \n",
    "        if (appear and row[i] ==1) :\n",
    "            count += 1 \n",
    "        \n",
    "        if  (row[i]==1 and i== len(row)-1):\n",
    "            count_list.append(count)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# EST\n",
    "def durations_rows(dict_info, dict_result,country):\n",
    "    lst_dfs= []\n",
    "    \n",
    "    for key, dicc in dict_info.items():\n",
    "        lista = []\n",
    "        df_counts = pd.DataFrame(columns=['Top','Category','Count','Country'])\n",
    "        data= dicc.loc[:,retrieved_date_data].values\n",
    "        np.apply_along_axis(func1d=count_durations_by_appearance, axis=1, arr= data, count_list = lista)\n",
    "        \n",
    "        df_counts['Count']= lista \n",
    "        df_counts['Top']= key[0]\n",
    "        df_counts['Category']= key[1] \n",
    "        df_counts['Country']= country.upper() \n",
    "        \n",
    "        lst_dfs.append(df_counts)\n",
    "    \n",
    "    dict_result[country]= pd.concat(lst_dfs) \n",
    "#     return pd.concat(lst_dfs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dict_counts = {}\n",
    "durations_rows(dict_pivot_cat_br, dict_counts,'br' )\n",
    "durations_rows(dict_pivot_cat_co, dict_counts,'co' )\n",
    "durations_rows(dict_pivot_cat_de, dict_counts,'de' )\n",
    "durations_rows(dict_pivot_cat_usa, dict_counts,'us' )\n",
    "df_counts_countries = pd.concat([dict_counts['br'],dict_counts['co'],dict_counts['de'],dict_counts['us']])\n",
    "df_counts_countries['Type']='EST'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_apps.id.nunique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TBSE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_durations_between_appearance(row, count_list):\n",
    "    count = 0\n",
    "    appear = False\n",
    "    once = False\n",
    "\n",
    "    for i in range(0,len(row)):\n",
    "        \n",
    "        if (not appear  and row[i]==1) :\n",
    "            appear = True\n",
    "            once=True\n",
    "            \n",
    "            if count !=0:\n",
    "                count_list.append(count)\n",
    "                count = 0  \n",
    "                \n",
    "        elif (np.isnan(row[i]) or row[i] ==0) and once:\n",
    "            \n",
    "            appear = False\n",
    "            count += 1\n",
    "\n",
    "def durations_between_appearance(dict_info, dict_result, country):\n",
    "    lst_dfs= []\n",
    "    \n",
    "    for (top,category), dicc in dict_info.items():\n",
    "        lista = []\n",
    "        df_counts = pd.DataFrame(columns=['Top','Category','Between_apps','Country'])\n",
    "        data= dicc.loc[:,retrieved_date_data].values\n",
    "        np.apply_along_axis(func1d=count_durations_between_appearance, axis=1, arr= data, count_list = lista)\n",
    "\n",
    "        df_counts['Between_apps']= lista \n",
    "        df_counts['Top']= top\n",
    "        df_counts['Category']= category\n",
    "        df_counts['Country']= country.upper() \n",
    "        lst_dfs.append(df_counts)\n",
    "    \n",
    "    dict_result[country]= pd.concat(lst_dfs) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dict_time_between_appearance = {}\n",
    "# \n",
    "durations_between_appearance(dict_pivot_cat_br, dict_time_between_appearance,'br' )\n",
    "durations_between_appearance(dict_pivot_cat_co, dict_time_between_appearance,'co' )\n",
    "durations_between_appearance(dict_pivot_cat_de, dict_time_between_appearance,'de' )\n",
    "durations_between_appearance(dict_pivot_cat_usa, dict_time_between_appearance,'us' )\n",
    "\n",
    "\n",
    "df_time_between_countries = pd.concat([dict_time_between_appearance['br'],dict_time_between_appearance['co'],dict_time_between_appearance['de'],dict_time_between_appearance['us']])\n",
    "df_time_between_countries = df_time_between_countries.reset_index(drop=True)\n",
    "df_time_between_countries['Type']='TBSE'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stats and graphics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#-------------------------------- Stats\n",
    "def manWhitney_pairs(data,column,numeric_column, list_categories, c_type=None):\n",
    "    p_values= {}\n",
    "    u_values={}\n",
    "    \n",
    "    for i in range(len(list_categories)):\n",
    "        par= list_categories[i]\n",
    "        for j in range(i+1, len(list_categories)):\n",
    "            par2 = list_categories[j]\n",
    "            \n",
    "            if  c_type:\n",
    "                par = par.upper()\n",
    "                par2= par2.upper()\n",
    "                \n",
    "            stat, p = mannwhitneyu(data[data[column]==par][numeric_column], data[data[column]==par2][numeric_column], alternative='two-sided')\n",
    "            p_values[f'{par}___{par2}']= p\n",
    "            u_values[f'{par}___{par2}']= stat\n",
    "    \n",
    "    return (p_values, u_values)\n",
    "\n",
    "def cliffsDelta_pairs(data, column,numeric_column, list_categories, key_bool_vals=None, c_type=None):\n",
    "    differences= {}\n",
    "        \n",
    "    for i in range(len(list_categories)):\n",
    "        par= list_categories[i]\n",
    "        for j in range(i+1, len(list_categories)):\n",
    "            par2 = list_categories[j]\n",
    "            if  c_type:\n",
    "                par = par.upper()\n",
    "                par2= par2.upper()\n",
    "                \n",
    "            if key_bool_vals  :\n",
    "                if key_bool_vals[f'{par}___{par2}']:\n",
    "                    d, res = cliffsDelta.cliffsDelta(data[data[column]==par][numeric_column], data[data[column]==par2][numeric_column])\n",
    "                    differences[f'{par}___{par2}']= (res, d)\n",
    "            else:\n",
    "                d, res = cliffsDelta.cliffsDelta(data[data[column]==par][numeric_column], data[data[column]==par2][numeric_column])\n",
    "                differences[f'{par}___{par2}']= (res, d)\n",
    "    \n",
    "    return differences\n",
    "#--------------------------------------- Summary\n",
    "def cat_df_summary(dict_differences, corrected_vals, column):\n",
    "    df=  pd.DataFrame(columns=['Col1','Col2',column,'Reject_h0','Difference','Difference_#'])\n",
    "    \n",
    "\n",
    "    df[column]= corrected_vals[1]\n",
    "    df['Col1']= [key.split('___')[0]for key in dict_differences.keys()]\n",
    "    df['Col2']= [key.split('___')[1]for key in dict_differences.keys()]\n",
    "    df['Reject_h0']=  corrected_vals[0]   \n",
    "    \n",
    "    df['Difference']= [v_tuple[0] for v_tuple in dict_differences.values()]\n",
    "    df['Difference_#']= [v_tuple[1] for v_tuple in dict_differences.values()]\n",
    "\n",
    "    return df\n",
    "\n",
    "# ----------------------------------------Graphics\n",
    "from matplotlib.patches import PathPatch\n",
    "\n",
    "def adjust_box_widths(g, fac):\n",
    "    \"\"\"\n",
    "    Adjust the withs of a seaborn-generated boxplot. \n",
    "    # From stackoverflow\n",
    "    \"\"\"\n",
    "\n",
    "    # iterating through Axes instances\n",
    "    for ax in g.axes:\n",
    "\n",
    "        # iterating through axes artists:\n",
    "        for c in ax.get_children():\n",
    "\n",
    "            # searching for PathPatches\n",
    "            if isinstance(c, PathPatch):\n",
    "                # getting current width of box:\n",
    "                p = c.get_path()\n",
    "                verts = p.vertices\n",
    "                verts_sub = verts[:-1]\n",
    "                ymin = np.min(verts_sub[:, 1])\n",
    "                ymax = np.max(verts_sub[:, 1])\n",
    "                ymid = 0.5*(ymin+ymax)\n",
    "                yhalf = 0.5*(ymax - ymin)\n",
    "\n",
    "                # setting new width of box\n",
    "                ymin_new = ymid-fac*yhalf\n",
    "                ymax_new = ymid+fac*yhalf\n",
    "                verts_sub[verts_sub[:, 1] == ymin, 1] = ymin_new\n",
    "                verts_sub[verts_sub[:, 1] == ymax, 1] = ymax_new\n",
    "\n",
    "                # setting new width of median line\n",
    "                for l in ax.lines:\n",
    "                    if np.all(l.get_ydata() == [ymin, ymax]):\n",
    "                        l.set_ydata([ymin_new, ymax_new])\n",
    "                        \n",
    "def title(word):\n",
    "    words = word.split(\"_\")\n",
    "    n_word= ''\n",
    "    for w in words:\n",
    "        if w != 'and':\n",
    "            n_word = n_word +\" \" +w.title()\n",
    "        else:\n",
    "            n_word = n_word + \" \" + w\n",
    "    return n_word"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TLO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## By country"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#fig= plt.figure(figsize=(9, 7))\n",
    "fig = plt.figure(figsize=(10, 4))\n",
    "\n",
    "sns.set_style(\"whitegrid\")\n",
    "ax = sns.boxplot(y=\"Country\", x=\"Occurrences\",\n",
    "                  data=df_occurences_countries, palette=seq_col_brew[1:],fliersize=3)\n",
    " \n",
    "ax.set_ylabel(\"Country\", fontsize=18)\n",
    "ax.set_xlabel(\"Occurences\",fontsize=18)\n",
    "ax.tick_params(labelsize=14)\n",
    "\n",
    "adjust_box_widths(fig,0.7)\n",
    "\n",
    "# plt.legend(bbox_to_anchor=(1.01, 1), loc=2, borderaxespad=0.)\n",
    "plt.tight_layout()\n",
    "\n",
    "fig.savefig(\"TLO_country.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_occurences_countries.groupby(['Country'])['Occurrences'].agg(pd.Series.mode)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "des_TLO_countries = df_occurences_countries.groupby('Country').describe().reset_index()\n",
    "des_TLO_countries.columns = des_TLO_countries.columns.droplevel()\n",
    "des_TLO_countries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import skew \n",
    "print(\n",
    "skew(df_occurences_countries[df_occurences_countries['Country']=='CO']['Occurrences']),\n",
    "skew(df_occurences_countries[df_occurences_countries['Country']=='BR']['Occurrences']),\n",
    "skew(df_occurences_countries[df_occurences_countries['Country']=='DE']['Occurrences']),\n",
    "skew(df_occurences_countries[df_occurences_countries['Country']=='US']['Occurrences']))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p_values, u_values= manWhitney_pairs(df_occurences_countries, 'Country','Occurrences',countries, c_type='CON')\n",
    "p_adjusted = multipletests(list(p_values.values()), alpha=0.05, method='holm')\n",
    "key_values= dict(zip(list(p_values.keys()), p_adjusted[0]))\n",
    "\n",
    "differences= cliffsDelta_pairs(df_occurences_countries, 'Country','Occurrences', countries,c_type='CON')\n",
    "df_summary_cont= cat_df_summary(differences,p_adjusted,'p_value')\n",
    "\n",
    "\n",
    "print(list(p_values.keys()))\n",
    "print(p_adjusted[0])\n",
    "print(p_adjusted[1])\n",
    "\n",
    "print(\"\\n\")\n",
    "\n",
    "print(\"Effect size\")\n",
    "print(differences)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## By top"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(10, 4))\n",
    "sns.set_style(\"whitegrid\")\n",
    "ax = sns.boxplot(y=\"Top\", x=\"Occurrences\",\n",
    "                  data=df_occurences_countries, palette=seq_col_brew[1:], fliersize=3)\n",
    "for box in ax.artists:\n",
    "    box.set_facecolor(\"white\")\n",
    "    \n",
    "\n",
    "ax.set_ylabel(\"\", fontsize=1)\n",
    "ax.set_xlabel(\"Occurences\",fontsize=18)\n",
    "ax.tick_params(labelsize=14)\n",
    "\n",
    "texts = [t.get_text()  for t in ax.get_yticklabels()]\n",
    "\n",
    "ticks = {'topFree':'Top free', 'topSelling':'Top Selling', 'editorChoice': \"Editor's choice\"}\n",
    "ax.set_yticklabels([ ticks[t] for t in texts])\n",
    "\n",
    "\n",
    "adjust_box_widths(fig,0.7)\n",
    "\n",
    "# plt.legend(bbox_to_anchor=(1.01, 1), loc=2, borderaxespad=0.)\n",
    "plt.tight_layout()\n",
    "\n",
    "fig.savefig(\"TLO_top.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "des_TLO_top = df_occurences_countries.groupby('Top').describe().reset_index()\n",
    "des_TLO_top.columns = des_TLO_top.columns.droplevel()\n",
    "des_TLO_top"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\n",
    "skew(df_occurences_countries[df_occurences_countries['Top']=='topFree']['Occurrences']),\n",
    "skew(df_occurences_countries[df_occurences_countries['Top']=='topSelling']['Occurrences']),\n",
    "skew(df_occurences_countries[df_occurences_countries['Top']=='editorChoice']['Occurrences']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p_values, u_values= manWhitney_pairs(df_occurences_countries,'Top','Occurrences',top)\n",
    "p_adjusted = multipletests(list(p_values.values()), alpha=0.05, method='holm')\n",
    "key_values= dict(zip(list(p_values.keys()), p_adjusted[0]))\n",
    "\n",
    "differences= cliffsDelta_pairs(df_occurences_countries,'Top','Occurrences',top, key_values)\n",
    "df_summary_top= cat_df_summary(differences,p_adjusted,'p_value')\n",
    "\n",
    "\n",
    "\n",
    "print(list(p_values.keys()))\n",
    "print(p_adjusted[0])\n",
    "print(p_adjusted[1])\n",
    "\n",
    "print(\"\\n\")\n",
    "\n",
    "print(\"Effect size\")\n",
    "print(differences)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## By category "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_cat_no_editorChoice = np.delete(clean_cat_no_editorChoice, np.where(clean_cat_no_editorChoice == \"general\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(16, 6))\n",
    "sns.set_style(\"whitegrid\")\n",
    "data = df_occurences_countries[(df_occurences_countries['Top'] != 'editorChoice') &  (df_occurences_countries['Category'] != 'general')\n",
    "\n",
    "#                            &(df_counts_countries['Category'] != 'general')\n",
    "                          ]\n",
    "ax = sns.boxplot(x=\"Category\", y=\"Occurrences\",\n",
    "                  data=data)\n",
    "for box in ax.artists:\n",
    "    box.set_facecolor(\"white\")\n",
    "plt.xticks(rotation=90)\n",
    "plt.tight_layout()                                                                                                    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "des_TLO_category = data.groupby('Category').describe().reset_index()\n",
    "des_TLO_category.columns = des_TLO_category.columns.droplevel()\n",
    "des_TLO_category"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "p_values, u_values= manWhitney_pairs(data,'Category','Occurrences',clean_cat_no_editorChoice)\n",
    "p_adjusted = multipletests(list(p_values.values()), alpha=0.05, method='holm')\n",
    "differences= cliffsDelta_pairs(data,'Category','Occurrences',clean_cat_no_editorChoice)\n",
    "df_summary_categories= cat_df_summary(differences,p_adjusted,'p_value')\n",
    "\n",
    "\n",
    "# print(list(p_values.keys()))\n",
    "print(p_adjusted[0])\n",
    "# print(p_adjusted[1])\n",
    "\n",
    "print(\"\\n\")\n",
    "\n",
    "print(\"Effect size\")\n",
    "# print(differences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "h0_rejected= df_summary_categories[df_summary_categories['Reject_h0']]\n",
    "pivot = pd.pivot_table(h0_rejected, index= ['Col1'], columns= ['Col2'], values= 'p_value')\n",
    "pivot2 = pd.pivot_table(h0_rejected, index= ['Col1'], columns= ['Col2'], values= 'Difference_#')\n",
    "\n",
    "print(set(pivot.index) - set(pivot.columns))\n",
    "print(set(pivot.columns) - set(pivot.index))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pivot3= h0_rejected[['Col1','Col2','Difference']].set_index(['Col1','Col2'],inplace=False)\n",
    "pivot3=pivot3.unstack()\n",
    "pivot3.columns = pivot3.columns.droplevel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pivot['maps_and_navigation']= np.nan\n",
    "pivot['house_and_home']= np.nan\n",
    "pivot['lifestyle']= np.nan\n",
    "pivot['health_and_fitness']= np.nan\n",
    "\n",
    "pivot= pivot.append(pd.Series(name='finance'))\n",
    "pivot= pivot.append(pd.Series(name='food_and_drink'))\n",
    "\n",
    "pivot.sort_index(inplace=True)\n",
    "pivot= pivot.reindex(sorted(pivot.columns), axis=1)\n",
    "\n",
    "pivot2['maps_and_navigation']= np.nan\n",
    "pivot2['house_and_home']= np.nan\n",
    "pivot2['lifestyle']= np.nan\n",
    "pivot2['health_and_fitness']= np.nan\n",
    "\n",
    "pivot2= pivot2.append(pd.Series(name='finance'))\n",
    "pivot2= pivot2.append(pd.Series(name='food_and_drink'))\n",
    "\n",
    "pivot2.sort_index(inplace=True)\n",
    "pivot2= pivot2.reindex(sorted(pivot2.columns), axis=1)\n",
    "\n",
    "pivot3['maps_and_navigation']= np.nan\n",
    "pivot3['house_and_home']= np.nan\n",
    "pivot3['lifestyle']= np.nan\n",
    "pivot3['health_and_fitness']= np.nan\n",
    "\n",
    "pivot3= pivot3.append(pd.Series(name='finance'))\n",
    "pivot3= pivot3.append(pd.Series(name='food_and_drink'))\n",
    "\n",
    "pivot3.sort_index(inplace=True)\n",
    "pivot3= pivot3.reindex(sorted(pivot3.columns), axis=1)\n",
    "\n",
    "\n",
    "\n",
    "# create square matrix \n",
    "for row in pivot.index:\n",
    "    for column in pivot.index:\n",
    "        if np.isnan(pivot.loc[row,column]):\n",
    "            pivot.loc[row,column]= pivot.loc[column,row] \n",
    "\n",
    "# create square matrix \n",
    "for row in pivot2.index:\n",
    "    for column in pivot2.index:\n",
    "        if np.isnan(pivot2.loc[row,column]):\n",
    "            pivot2.loc[row,column]= pivot2.loc[column,row] \n",
    "            \n",
    "# create square matrix \n",
    "for row in pivot3.index:\n",
    "    for column in pivot3.index:\n",
    "        if pd.isnull(pivot3.loc[row,column]):\n",
    "            pivot3.loc[row,column]= pivot3.loc[column,row] \n",
    "        if pivot3.loc[row,column] =='small':\n",
    "            pivot3.loc[row,column] = 'S'\n",
    "        elif pivot3.loc[row,column] =='medium':\n",
    "            pivot3.loc[row,column] = 'M'\n",
    "        elif pivot3.loc[row,column] =='large':\n",
    "            pivot3.loc[row,column] = 'L'\n",
    "        elif pivot3.loc[row,column] =='negligible':\n",
    "            pivot3.loc[row,column] = 'N'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set(style=\"white\")\n",
    "\n",
    "# Generate a mask for the upper triangle\n",
    "mask = np.triu(np.ones_like(pivot, dtype=np.bool))\n",
    "\n",
    "# Set up the matplotlib figure\n",
    "fig, ax = plt.subplots(figsize=(11, 10))\n",
    "\n",
    "\n",
    "# cbar_ax = fig.add_axes()\n",
    "\n",
    "cbar_ax = fig.add_axes([.85, .55, .02, .4])\n",
    "\n",
    "\n",
    "# Draw the heatmap with the mask and correct aspect ratio\n",
    "ax= sns.heatmap(pivot, mask=mask, cmap='Greys_r', center=0.035,\n",
    "            square=True, linewidths=0.6,vmax=0.05,  vmin=0, ax=ax, cbar_ax=cbar_ax, annot = pivot3.values, fmt = '',\n",
    "                cbar_kws={\"shrink\": .5, }, \n",
    "                annot_kws={\"size\": 14, })\n",
    "\n",
    "\n",
    "\n",
    "ax.set_ylabel(\"\", fontsize=1)\n",
    "ax.set_xlabel(\"\",fontsize=1)\n",
    "ax.tick_params(labelsize=15)\n",
    "\n",
    "texts = [t.get_text()  for t in ax.get_yticklabels()]\n",
    "\n",
    "# ticks = {'topFree':'Top free', 'topSelling':'Top Selling', 'editorChoice': \"Editor's choice\"}\n",
    "ax.set_yticklabels([ title(t) for t in texts])\n",
    "ax.set_xticklabels([ title(t) for t in texts])\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "cbar_ax.tick_params(labelsize=14)\n",
    "\n",
    "fig = ax.get_figure()\n",
    "plt.tight_layout()\n",
    "\n",
    "\n",
    "fig.savefig(\"TLO_category.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_summary_categories.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_summary_categories[df_summary_categories.Reject_h0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_summary_categories[(df_summary_categories.Reject_h0)& (df_summary_categories.Difference != 'negligible')].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x =pd.DataFrame(df_summary_categories[(df_summary_categories.Reject_h0)& (df_summary_categories.Difference != 'negligible')].Col2.value_counts()).join(pd.DataFrame(df_summary_categories[(df_summary_categories.Reject_h0)& (df_summary_categories.Difference != 'negligible')].Col1.value_counts()) )\n",
    "x.Col1 + x.Col2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## EST"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## By country"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(9, 7))\n",
    "\n",
    "sns.set_style(\"whitegrid\")\n",
    "ax = sns.boxplot(x=\"Country\", y=\"Count\", data=df_counts_countries, palette=seq_col_brew[1:], width=0.5)\n",
    "\n",
    "fig = ax.get_figure()\n",
    "fig.savefig(\"EST_country.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "des_DTLO_countries = df_counts_countries.groupby('Country').describe().reset_index()\n",
    "des_DTLO_countries.columns = des_DTLO_countries.columns.droplevel()\n",
    "des_DTLO_countries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p_values, u_values= manWhitney_pairs(df_counts_countries, 'Country','Count',countries, c_type='CON')\n",
    "p_adjusted = multipletests(list(p_values.values()), alpha=0.05, method='holm')\n",
    "differnces= cliffsDelta_pairs(df_counts_countries, 'Country','Count',countries, c_type='CON')\n",
    "\n",
    "print(list(p_values.keys()))\n",
    "print(p_adjusted[0])\n",
    "print(p_adjusted[1])\n",
    "\n",
    "print(\"\\n\")\n",
    "\n",
    "print(\"Effect size\")\n",
    "print(differnces)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## By top"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(9, 7))\n",
    "sns.set_style(\"whitegrid\")\n",
    "ax = sns.boxplot(x=\"Top\", y=\"Count\",\n",
    "                  data=df_counts_countries, palette=seq_col_brew[1:],  width=0.5)\n",
    "for box in ax.artists:\n",
    "    box.set_facecolor(\"white\")\n",
    "fig = ax.get_figure()\n",
    "fig.savefig(\"EST_top.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "des_DTLO_top = df_counts_countries.groupby('Top').describe().reset_index()\n",
    "des_DTLO_top.columns = des_DTLO_top.columns.droplevel()\n",
    "des_DTLO_top"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import skew \n",
    "\n",
    "print(\n",
    "skew(df_counts_countries[df_counts_countries['Top']=='topFree']['Count']),\n",
    "skew(df_counts_countries[df_counts_countries['Top']=='topSelling']['Count']),\n",
    "skew(df_counts_countries[df_counts_countries['Top']=='editorChoice']['Count']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p_values, u_values= manWhitney_pairs(df_counts_countries,'Top','Count',top)\n",
    "p_adjusted = multipletests(list(p_values.values()), alpha=0.05, method='holm')\n",
    "differences= cliffsDelta_pairs(df_counts_countries,'Top','Count',top)\n",
    "\n",
    "print(list(p_values.keys()))\n",
    "print(p_adjusted[0])\n",
    "print(p_adjusted[1])\n",
    "\n",
    "print(\"\\n\")\n",
    "\n",
    "print(\"Effect size\")\n",
    "print(differences)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## By category "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(16, 6))\n",
    "sns.set_style(\"whitegrid\")\n",
    "data = df_counts_countries[(df_counts_countries['Top'] != 'editorChoice') & (df_counts_countries['Category'] != 'general')\n",
    "#                            &(df_counts_countries['Category'] != 'general')\n",
    "                          ]\n",
    "ax = sns.boxplot(x=\"Category\", y=\"Count\",\n",
    "                  data=data,  width=0.5)\n",
    "for box in ax.artists:\n",
    "    box.set_facecolor(\"white\")\n",
    "plt.xticks(rotation=90)\n",
    "plt.tight_layout()                                                                                                    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.Category.nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "des_DTLO_category = data.groupby('Category').describe().reset_index()\n",
    "des_DTLO_category.columns = des_DTLO_category.columns.droplevel()\n",
    "des_DTLO_category"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p_values, u_values= manWhitney_pairs(data,'Category','Count',clean_cat_no_editorChoice)\n",
    "p_adjusted = multipletests(list(p_values.values()), alpha=0.05, method='holm')\n",
    "differences= cliffsDelta_pairs(data,'Category','Count',clean_cat_no_editorChoice)\n",
    "df_summary_categories= cat_df_summary(differences,p_adjusted,'p_value')\n",
    "# print(list(p_values.keys()))\n",
    "# print(p_adjusted[0])\n",
    "# print(p_adjusted[1])\n",
    "\n",
    "print(\"\\n\")\n",
    "\n",
    "print(\"Effect size\")\n",
    "# print(differences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "h0_rejected= df_summary_categories[df_summary_categories['Reject_h0']]\n",
    "pivot = pd.pivot_table(h0_rejected, index= ['Col1'], columns= ['Col2'], values= 'p_value')\n",
    "pivot2 = pd.pivot_table(h0_rejected, index= ['Col1'], columns= ['Col2'], values= 'Difference_#')\n",
    "\n",
    "print(set(pivot.index) - set(pivot.columns))\n",
    "print(set(pivot.columns) - set(pivot.index))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pivot3= h0_rejected[['Col1','Col2','Difference']].set_index(['Col1','Col2'],inplace=False)\n",
    "pivot3=pivot3.unstack()\n",
    "pivot3.columns = pivot3.columns.droplevel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pivot['health_and_fitness']= np.nan\n",
    "pivot= pivot.append(pd.Series(name='food_and_drink'))\n",
    "\n",
    "pivot.sort_index(inplace=True)\n",
    "pivot= pivot.reindex(sorted(pivot.columns), axis=1)\n",
    "\n",
    "# create square matrix \n",
    "for row in pivot.index:\n",
    "    for column in pivot.index:\n",
    "        if np.isnan(pivot.loc[row,column]):\n",
    "            pivot.loc[row,column]= pivot.loc[column,row] \n",
    "            \n",
    "            \n",
    "pivot2['health_and_fitness']= np.nan\n",
    "\n",
    "           \n",
    "pivot2= pivot2.append(pd.Series(name='food_and_drink'))\n",
    "\n",
    "pivot2.sort_index(inplace=True)\n",
    "pivot2= pivot2.reindex(sorted(pivot2.columns), axis=1)\n",
    "\n",
    "pivot3['health_and_fitness']= np.nan\n",
    "\n",
    "pivot3= pivot3.append(pd.Series(name='food_and_drink'))\n",
    "\n",
    "pivot3.sort_index(inplace=True)\n",
    "pivot3= pivot3.reindex(sorted(pivot3.columns), axis=1)\n",
    "\n",
    "\n",
    "\n",
    "# create square matrix \n",
    "for row in pivot.index:\n",
    "    for column in pivot.index:\n",
    "        if np.isnan(pivot.loc[row,column]):\n",
    "            pivot.loc[row,column]= pivot.loc[column,row] \n",
    "\n",
    "# create square matrix \n",
    "for row in pivot2.index:\n",
    "    for column in pivot2.index:\n",
    "        if np.isnan(pivot2.loc[row,column]):\n",
    "            pivot2.loc[row,column]= pivot2.loc[column,row] \n",
    "            \n",
    "# create square matrix \n",
    "for row in pivot3.index:\n",
    "    for column in pivot3.index:\n",
    "        if pd.isnull(pivot3.loc[row,column]):\n",
    "            pivot3.loc[row,column]= pivot3.loc[column,row] \n",
    "        if pivot3.loc[row,column] =='small':\n",
    "            pivot3.loc[row,column] = 'S'\n",
    "        elif pivot3.loc[row,column] =='medium':\n",
    "            pivot3.loc[row,column] = 'M'\n",
    "        elif pivot3.loc[row,column] =='large':\n",
    "            pivot3.loc[row,column] = 'L'\n",
    "        elif pivot3.loc[row,column] =='negligible':\n",
    "            pivot3.loc[row,column] = 'N'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set(style=\"white\")\n",
    "\n",
    "# Generate a mask for the upper triangle\n",
    "mask = np.triu(np.ones_like(pivot, dtype=np.bool))\n",
    "\n",
    "# Set up the matplotlib figure\n",
    "fig, ax = plt.subplots(figsize=(11, 10))\n",
    "\n",
    "\n",
    "# cbar_ax = fig.add_axes()\n",
    "\n",
    "cbar_ax = fig.add_axes([.85, .55, .02, .4])\n",
    "\n",
    "\n",
    "# Draw the heatmap with the mask and correct aspect ratio\n",
    "ax= sns.heatmap(pivot, mask=mask, cmap='Greys_r', center=0.035,\n",
    "            square=True, linewidths=0.6,vmax=0.05,  vmin=0, ax=ax, cbar_ax=cbar_ax, annot = pivot3.values, fmt = '',\n",
    "                cbar_kws={\"shrink\": .5, }, \n",
    "                annot_kws={\"size\": 14, })\n",
    "\n",
    "\n",
    "\n",
    "ax.set_ylabel(\"\", fontsize=1)\n",
    "ax.set_xlabel(\"\",fontsize=1)\n",
    "ax.tick_params(labelsize=15)\n",
    "\n",
    "texts = [t.get_text()  for t in ax.get_yticklabels()]\n",
    "\n",
    "# ticks = {'topFree':'Top free', 'topSelling':'Top Selling', 'editorChoice': \"Editor's choice\"}\n",
    "ax.set_yticklabels([ title(t) for t in texts])\n",
    "ax.set_xticklabels([ title(t) for t in texts])\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "cbar_ax.tick_params(labelsize=14)\n",
    "\n",
    "fig = ax.get_figure()\n",
    "plt.tight_layout()\n",
    "\n",
    "fig.savefig(\"EST_category.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_summary_categories[(df_summary_categories.Reject_h0)].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_summary_categories[(df_summary_categories.Reject_h0)& (df_summary_categories.Difference != 'negligible')].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = pd.DataFrame(df_summary_categories[(df_summary_categories.Reject_h0)& (df_summary_categories.Difference != 'negligible')].Col1.value_counts()).join( pd.DataFrame(df_summary_categories[(df_summary_categories.Reject_h0)& (df_summary_categories.Difference != 'negligible')].Col2.value_counts()))\n",
    "x.fillna(0, inplace=True)\n",
    "x['Col1'] +  x['Col2']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TBSE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## By country"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_time_between_countries.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(16, 10))\n",
    "sns.set_style(\"whitegrid\")\n",
    "ax = sns.boxplot(x=\"Country\", y=\"Between_apps\",\n",
    "                  data=df_time_between_countries, palette=seq_col_brew[1:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "des_DBTLO_countries = df_time_between_countries.groupby('Country').describe().reset_index()\n",
    "des_DBTLO_countries.columns = des_DBTLO_countries.columns.droplevel()\n",
    "des_DBTLO_countries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p_values, u_values= manWhitney_pairs(df_time_between_countries, 'Country','Between_apps',countries, c_type='CON')\n",
    "p_adjusted = multipletests(list(p_values.values()), alpha=0.05, method='holm')\n",
    "differnces= cliffsDelta_pairs(df_time_between_countries, 'Country','Between_apps',countries, c_type='CON')\n",
    "\n",
    "print(list(p_values.keys()))\n",
    "print(p_adjusted[0])\n",
    "print(p_adjusted[1])\n",
    "\n",
    "print(\"\\n\")\n",
    "\n",
    "print(\"Effect size\")\n",
    "print(differnces)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## By top"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(9, 7))\n",
    "\n",
    "sns.set_style(\"whitegrid\")\n",
    "ax = sns.boxplot(x=\"Top\", y=\"Between_apps\",\n",
    "                  data=df_time_between_countries, palette=seq_col_brew[1:])\n",
    "for box in ax.artists:\n",
    "    box.set_facecolor(\"white\")\n",
    "    \n",
    "fig = ax.get_figure()\n",
    "fig.savefig(\"TBSE_top.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "des_DBTLO_top = df_time_between_countries.groupby('Top').describe().reset_index()\n",
    "des_DBTLO_top.columns = des_DBTLO_top.columns.droplevel()\n",
    "des_DBTLO_top"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import skew \n",
    "\n",
    "print(\n",
    "skew(df_time_between_countries[df_time_between_countries['Top']=='topFree']['Between_apps']),\n",
    "skew(df_time_between_countries[df_time_between_countries['Top']=='topSelling']['Between_apps']),\n",
    "skew(df_time_between_countries[df_time_between_countries['Top']=='editorChoice']['Between_apps']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p_values, u_values= manWhitney_pairs(df_time_between_countries,'Top','Between_apps',top)\n",
    "p_adjusted = multipletests(list(p_values.values()), alpha=0.05, method='holm')\n",
    "differences= cliffsDelta_pairs(df_time_between_countries,'Top','Between_apps',top)\n",
    "\n",
    "\n",
    "print(list(p_values.keys()))\n",
    "print(p_adjusted[0])\n",
    "print(p_adjusted[1])\n",
    "\n",
    "print(\"\\n\")\n",
    "\n",
    "print(\"Effect size\")\n",
    "print(differences)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## By category "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(16, 6))\n",
    "sns.set_style(\"whitegrid\")\n",
    "data = df_time_between_countries[(df_time_between_countries['Top'] != 'editorChoice') & (df_time_between_countries['Category'] != 'general')\n",
    "\n",
    "#                            &(df_counts_countries['Category'] != 'general')\n",
    "                          ]\n",
    "ax = sns.boxplot(x=\"Category\", y=\"Between_apps\",\n",
    "                  data=data)\n",
    "for box in ax.artists:\n",
    "    box.set_facecolor(\"white\")\n",
    "plt.xticks(rotation=90)\n",
    "plt.tight_layout()                                                                                                    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "des_DBTLO_category = data.groupby('Category').describe().reset_index()\n",
    "des_DBTLO_category.columns = des_DBTLO_category.columns.droplevel()\n",
    "des_DBTLO_category"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p_values, u_values= manWhitney_pairs(data,'Category','Between_apps',clean_cat_no_editorChoice)\n",
    "p_adjusted = multipletests(list(p_values.values()), alpha=0.05, method='holm')\n",
    "differences= cliffsDelta_pairs(data,'Category','Between_apps',clean_cat_no_editorChoice)\n",
    "df_summary_categories= cat_df_summary(differences,p_adjusted,'p_value')\n",
    "# print(list(p_values.keys()))\n",
    "# print(p_adjusted[0])\n",
    "# print(p_adjusted[1])\n",
    "\n",
    "# print(\"\\n\")\n",
    "\n",
    "# print(\"Effect size\")\n",
    "# print(differences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "h0_rejected= df_summary_categories[df_summary_categories['Reject_h0']]\n",
    "pivot = pd.pivot_table(h0_rejected, index= ['Col1'], columns= ['Col2'], values= 'p_value')\n",
    "pivot2 = pd.pivot_table(h0_rejected, index= ['Col1'], columns= ['Col2'], values= 'Difference_#')\n",
    "\n",
    "print(set(pivot.index) - set(pivot.columns))\n",
    "print(set(pivot.columns) - set(pivot.index))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pivot3= h0_rejected[['Col1','Col2','Difference']].set_index(['Col1','Col2'],inplace=False)\n",
    "pivot3=pivot3.unstack()\n",
    "pivot3.columns = pivot3.columns.droplevel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pivot['libraries_and_demo']= np.nan\n",
    "pivot['health_and_fitness']= np.nan\n",
    "\n",
    "pivot= pivot.append(pd.Series(name='finance'))\n",
    "pivot= pivot.append(pd.Series(name='food_and_drink'))\n",
    "pivot= pivot.append(pd.Series(name='comics'))\n",
    "pivot= pivot.append(pd.Series(name='entertainment'))\n",
    "pivot= pivot.append(pd.Series(name='education'))\n",
    "\n",
    "pivot.sort_index(inplace=True)\n",
    "pivot= pivot.reindex(sorted(pivot.columns), axis=1)\n",
    "\n",
    "# create square matrix \n",
    "for row in pivot.index:\n",
    "    for column in pivot.index:\n",
    "        if np.isnan(pivot.loc[row,column]):\n",
    "            pivot.loc[row,column]= pivot.loc[column,row] \n",
    "            \n",
    "            \n",
    "pivot2['libraries_and_demo']= np.nan\n",
    "pivot2['health_and_fitness']= np.nan\n",
    "\n",
    "\n",
    "pivot2= pivot2.append(pd.Series(name='finance'))\n",
    "pivot2= pivot2.append(pd.Series(name='food_and_drink'))\n",
    "pivot2= pivot2.append(pd.Series(name='comics'))\n",
    "pivot2= pivot2.append(pd.Series(name='entertainment'))\n",
    "pivot2= pivot2.append(pd.Series(name='education'))\n",
    "\n",
    "\n",
    "pivot2.sort_index(inplace=True)\n",
    "pivot2= pivot2.reindex(sorted(pivot2.columns), axis=1)\n",
    "\n",
    "pivot3['libraries_and_demo']= np.nan\n",
    "pivot3['health_and_fitness']= np.nan\n",
    "\n",
    "\n",
    "pivot3= pivot3.append(pd.Series(name='finance'))\n",
    "pivot3= pivot3.append(pd.Series(name='food_and_drink'))\n",
    "pivot3= pivot3.append(pd.Series(name='comics'))\n",
    "pivot3= pivot3.append(pd.Series(name='entertainment'))\n",
    "pivot3= pivot3.append(pd.Series(name='education'))\n",
    "\n",
    "\n",
    "pivot3.sort_index(inplace=True)\n",
    "pivot3= pivot3.reindex(sorted(pivot3.columns), axis=1)\n",
    "\n",
    "\n",
    "\n",
    "# create square matrix \n",
    "for row in pivot.index:\n",
    "    for column in pivot.index:\n",
    "        if np.isnan(pivot.loc[row,column]):\n",
    "            pivot.loc[row,column]= pivot.loc[column,row] \n",
    "\n",
    "# create square matrix \n",
    "for row in pivot2.index:\n",
    "    for column in pivot2.index:\n",
    "        if np.isnan(pivot2.loc[row,column]):\n",
    "            pivot2.loc[row,column]= pivot2.loc[column,row] \n",
    "            \n",
    "# create square matrix \n",
    "for row in pivot3.index:\n",
    "    for column in pivot3.index:\n",
    "        if pd.isnull(pivot3.loc[row,column]):\n",
    "            pivot3.loc[row,column]= pivot3.loc[column,row] \n",
    "        if pivot3.loc[row,column] =='small':\n",
    "            pivot3.loc[row,column] = 'S'\n",
    "        elif pivot3.loc[row,column] =='medium':\n",
    "            pivot3.loc[row,column] = 'M'\n",
    "        elif pivot3.loc[row,column] =='large':\n",
    "            pivot3.loc[row,column] = 'L'\n",
    "        elif pivot3.loc[row,column] =='negligible':\n",
    "            pivot3.loc[row,column] = 'N'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set(style=\"white\")\n",
    "\n",
    "# Generate a mask for the upper triangle\n",
    "mask = np.triu(np.ones_like(pivot, dtype=np.bool))\n",
    "\n",
    "# Set up the matplotlib figure\n",
    "fig, ax = plt.subplots(figsize=(11, 10))\n",
    "\n",
    "\n",
    "# cbar_ax = fig.add_axes()\n",
    "\n",
    "cbar_ax = fig.add_axes([.85, .55, .02, .4])\n",
    "\n",
    "\n",
    "# Draw the heatmap with the mask and correct aspect ratio\n",
    "ax= sns.heatmap(pivot, mask=mask, cmap='Greys_r', center=0.035,\n",
    "            square=True, linewidths=0.6,vmax=0.05,  vmin=0, ax=ax, cbar_ax=cbar_ax, annot = pivot3.values, fmt = '',\n",
    "                cbar_kws={\"shrink\": .5, }, \n",
    "                annot_kws={\"size\": 14, })\n",
    "\n",
    "ax.set_ylabel(\"\", fontsize=1)\n",
    "ax.set_xlabel(\"\",fontsize=1)\n",
    "ax.tick_params(labelsize=15)\n",
    "\n",
    "texts = [t.get_text()  for t in ax.get_yticklabels()]\n",
    "\n",
    "# ticks = {'topFree':'Top free', 'topSelling':'Top Selling', 'editorChoice': \"Editor's choice\"}\n",
    "ax.set_yticklabels([ title(t) for t in texts])\n",
    "ax.set_xticklabels([ title(t) for t in texts])\n",
    "\n",
    "cbar_ax.tick_params(labelsize=14)\n",
    "\n",
    "fig = ax.get_figure()\n",
    "plt.tight_layout()\n",
    "\n",
    "fig.savefig(\"TBSE_category.png\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_summary_categories[(df_summary_categories.Reject_h0)].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_summary_categories[(df_summary_categories.Reject_h0)& (df_summary_categories.Difference != 'negligible')].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = pd.DataFrame(df_summary_categories[(df_summary_categories.Reject_h0)& (df_summary_categories.Difference != 'negligible')].Col1.value_counts()).join( pd.DataFrame(df_summary_categories[(df_summary_categories.Reject_h0)& (df_summary_categories.Difference != 'negligible')].Col2.value_counts()))\n",
    "x.fillna(0, inplace=True)\n",
    "x['Col1'] +  x['Col2']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### EST and TBSE for Country and Top aggregation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_occurences_countries2 = df_occurences_countries.copy()\n",
    "df_occurences_countries2.columns = ['Top', 'Category', '# Events', 'Country', 'Type']\n",
    "df_counts_countries2 = df_counts_countries.copy()\n",
    "df_counts_countries2.columns = ['Top', 'Category', 'Weeks', 'Country', 'Event']\n",
    "df_time_between_countries2 = df_time_between_countries.copy()\n",
    "df_time_between_countries2.columns = ['Top', 'Category', 'Weeks', 'Country', 'Event']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "duration = pd.concat([df_time_between_countries2, df_counts_countries2], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig= plt.figure(figsize=(9, 6))\n",
    "\n",
    "sns.set_style(\"whitegrid\")\n",
    "ax = sns.boxplot(y=\"Event\", x=\"Weeks\", hue='Country',\n",
    "                  data=duration, palette=seq_col_brew[1:], order= ['EST','TBSE'])\n",
    "\n",
    "ax.set_xlabel(\"Weeks\", fontsize=15)\n",
    "ax.set_ylabel(\"Event\",fontsize=15)\n",
    "ax.tick_params(labelsize=15)\n",
    "adjust_box_widths(fig, 0.7)\n",
    "# fig.savefig(\"DTLO_country.png\")\n",
    "plt.legend(bbox_to_anchor=(1.01, 1), loc=2, borderaxespad=0., fontsize='15')\n",
    "\n",
    "fig = ax.get_figure()\n",
    "fig.savefig(\"country_event.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig= plt.figure(figsize=(10, 6))\n",
    "\n",
    "sns.set_style(\"whitegrid\")\n",
    "ax = sns.boxplot(y=\"Event\", x=\"Weeks\",  hue='Top',\n",
    "                  data=duration, palette='Greys', fliersize=3, order= ['EST','TBSE'])\n",
    "\n",
    "adjust_box_widths(fig, 0.7)\n",
    "\n",
    "ax.set_ylabel(\"\", fontsize=1)\n",
    "ax.set_xlabel(\"Weeks\",fontsize=18)\n",
    "ax.tick_params(labelsize=14)\n",
    "\n",
    "h, l = ax.get_legend_handles_labels()\n",
    "plt.legend(handles=h, labels=['Top selling', 'Top free', \"Editor's choice\"], fontsize='14')\n",
    "\n",
    "\n",
    "plt.tight_layout()\n",
    "fig = ax.get_figure()\n",
    "fig.savefig(\"top_events.png\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
